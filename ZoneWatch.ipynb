{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaFSrCX2fMp+15iW58cDPV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitneverdebugs/ZoneWatch/blob/main/ZoneWatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "P9Uv8ZUxkicC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ],
      "metadata": {
        "id": "CZImxMSlkjuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "NEDQOpP8klaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "\n",
        "%cd {HOME}/yolov5\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "-qB5AzfKknCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "gMEvusenkpTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import detectron2\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "ilwWPRk2ktiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision as sv\n",
        "print(\"supervision\", sv.__version__)"
      ],
      "metadata": {
        "id": "a_ShpVthkx0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision[assets] -q\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "jk_YzYUOkzWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from supervision.assets import download_assets, VideoAssets\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "download_assets(VideoAssets.MARKET_SQUARE)\n",
        "download_assets(VideoAssets.GROCERY_STORE)\n",
        "download_assets(VideoAssets.SUBWAY)\n",
        "\n",
        "\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "tHEPdANSk3q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8s.pt')"
      ],
      "metadata": {
        "id": "_iKnKOmHk57J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.GROCERY_STORE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "B4wM_be2k7og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.GROCERY_STORE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "detections = detections[detections.class_id == 0]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "Y3H89SXomA9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.GROCERY_STORE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "detections = detections[detections.class_id == 0]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "dXvt-BE8mHh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv.VideoInfo.from_video_path(VideoAssets.GROCERY_STORE.value)"
      ],
      "metadata": {
        "id": "JLBpE9pDmYTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [1900, 1250],\n",
        "    [2350, 1250],\n",
        "    [3500, 2160],\n",
        "    [1250, 2160]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.GROCERY_STORE.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=6, text_thickness=6, text_scale=4)\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.GROCERY_STORE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "detections = detections[detections.class_id == 0]\n",
        "zone.trigger(detections=detections)\n",
        "\n",
        "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "Ihd3bMp8meUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [1725, 1550],\n",
        "    [2725, 1550],\n",
        "    [3500, 2160],\n",
        "    [1250, 2160]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.GROCERY_STORE.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=6, text_thickness=6, text_scale=4)\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.GROCERY_STORE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, imgsz=1280)[0]\n",
        "detections = sv.Detections.from_ultralytics(results)\n",
        "detections = detections[detections.class_id == 0]\n",
        "zone.trigger(detections=detections)\n",
        "\n",
        "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "C5T8EU4qmgpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [1725, 1550],\n",
        "    [2725, 1550],\n",
        "    [3500, 2160],\n",
        "    [1250, 2160]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.GROCERY_STORE.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=6, text_thickness=6, text_scale=4)\n",
        "\n",
        "def process_frame(frame: np.ndarray, _) -> np.ndarray:\n",
        "    results = model(frame, imgsz=1280)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    detections = detections[detections.class_id == 0]\n",
        "    zone.trigger(detections=detections)\n",
        "\n",
        "    labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _, _ in detections]\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "    frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "    frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "    return frame\n",
        "\n",
        "sv.process_video(source_path=VideoAssets.GROCERY_STORE.value, target_path=f\"{HOME}/mall-result.mp4\", callback=process_frame)\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "sdFPMXR2mmDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "QiwSGpH4mtS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.SUBWAY.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "outputs = predictor(frame)\n",
        "detections = sv.Detections(\n",
        "    xyxy=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n",
        "    confidence=outputs[\"instances\"].scores.cpu().numpy(),\n",
        "    class_id=outputs[\"instances\"].pred_classes.cpu().numpy().astype(int)\n",
        ")\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "7Hd-cqpOnVkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "# extract video frame\n",
        "generator = sv.get_video_frames_generator(VideoAssets.SUBWAY.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "# detect\n",
        "outputs = predictor(frame)\n",
        "detections = sv.Detections(\n",
        "    xyxy=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n",
        "    confidence=outputs[\"instances\"].scores.cpu().numpy(),\n",
        "    class_id=outputs[\"instances\"].pred_classes.cpu().numpy().astype(int)\n",
        ")\n",
        "detections = detections[detections.class_id == 0]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "NeDsmcT2nZ2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv.VideoInfo.from_video_path(VideoAssets.SUBWAY.value)"
      ],
      "metadata": {
        "id": "rgUQxeH3ngYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [200, 3840],\n",
        "    [1300, 600],\n",
        "    [1325, 600],\n",
        "    [550, 3840]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.SUBWAY.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=6, text_thickness=6, text_scale=4)\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.SUBWAY.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "outputs = predictor(frame)\n",
        "detections = sv.Detections(\n",
        "    xyxy=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n",
        "    confidence=outputs[\"instances\"].scores.cpu().numpy(),\n",
        "    class_id=outputs[\"instances\"].pred_classes.cpu().numpy().astype(int)\n",
        ")\n",
        "detections = detections[detections.class_id == 0]\n",
        "zone.trigger(detections=detections)\n",
        "\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "hTSvau8AnkJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [200, 3840],\n",
        "    [1300, 600],\n",
        "    [1325, 600],\n",
        "    [550, 3840]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.SUBWAY.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=6, text_thickness=6, text_scale=4)\n",
        "\n",
        "def process_frame(frame: np.ndarray, i: int) -> np.ndarray:\n",
        "    outputs = predictor(frame)\n",
        "    detections = sv.Detections(\n",
        "        xyxy=outputs[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n",
        "        confidence=outputs[\"instances\"].scores.cpu().numpy(),\n",
        "        class_id=outputs[\"instances\"].pred_classes.cpu().numpy().astype(int)\n",
        "    )\n",
        "    detections = detections[detections.class_id == 0]\n",
        "    zone.trigger(detections=detections)\n",
        "\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "    frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "    return frame\n",
        "\n",
        "sv.process_video(source_path=VideoAssets.SUBWAY.value, target_path=f\"{HOME}/subway-result.mp4\", callback=process_frame)\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "hkCDoO1anmXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5x6')"
      ],
      "metadata": {
        "id": "jwe0YzcDnsq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "KLlfrh4MppES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "D0MhU9KqpxPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(detections)"
      ],
      "metadata": {
        "id": "22UXGwJFp2Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [0, 0],\n",
        "    [1080 - 5, 0],\n",
        "    [1080 - 5, 1300 - 5],\n",
        "    [0, 1300 - 5]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "mask = zone.trigger(detections=detections)\n",
        "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5) & mask]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = sv.draw_polygon(scene=frame, polygon=polygon, color=sv.Color.ROBOFLOW, thickness=6)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "Yq3JjLR5p4kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)"
      ],
      "metadata": {
        "id": "mHD8HE-kp7hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "polygon = np.array([\n",
        "    [540,  985],\n",
        "    [1620, 985],\n",
        "    [2160, 1920],\n",
        "    [1620, 2855],\n",
        "    [540,  2855],\n",
        "    [0,    1920]\n",
        "])\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
        "zone = sv.PolygonZone(polygon=polygon)\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "mask = zone.trigger(detections=detections)\n",
        "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5) & mask]\n",
        "\n",
        "box_annotator = sv.BoundingBoxAnnotator(thickness=4)\n",
        "label_annotator = sv.LabelAnnotator(text_thickness=4, text_scale=2)\n",
        "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = label_annotator.annotate(scene=frame, detections=detections)\n",
        "frame = sv.draw_polygon(scene=frame, polygon=polygon, color=sv.Color.ROBOFLOW, thickness=6)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "0AwkfKrjp9s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sv.ColorPalette.DEFAULT\n",
        "polygons = [\n",
        "    np.array([\n",
        "        [0, 0],\n",
        "        [1080 - 5, 0],\n",
        "        [1080 - 5, 1300 - 5],\n",
        "        [0, 1300 - 5]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1080 + 5, 0],\n",
        "        [2160, 0],\n",
        "        [2160, 1300 - 5],\n",
        "        [1080 + 5, 1300 - 5]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [0, 1300 + 5],\n",
        "        [1080 - 5, 1300 + 5],\n",
        "        [1080 - 5, 3840],\n",
        "        [0, 3840]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1080 + 5, 1300 + 5],\n",
        "        [2160, 1300 + 5],\n",
        "        [2160, 3840],\n",
        "        [1080 + 5, 3840]\n",
        "    ], np.int32)\n",
        "]\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
        "\n",
        "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
        "zone_annotators = [\n",
        "    sv.PolygonZoneAnnotator(\n",
        "        zone=zone,\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=4,\n",
        "        text_thickness=8,\n",
        "        text_scale=4\n",
        "    )\n",
        "    for index, zone\n",
        "    in enumerate(zones)\n",
        "]\n",
        "box_annotators = [\n",
        "    sv.BoundingBoxAnnotator(\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=4,\n",
        "    )\n",
        "    for index\n",
        "    in range(len(polygons))\n",
        "]\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
        "\n",
        "for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
        "    mask = zone.trigger(detections=detections)\n",
        "    detections_filtered = detections[mask]\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
        "    frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "i9FcnN24p_aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sv.ColorPalette.DEFAULT\n",
        "polygons = [\n",
        "    np.array([\n",
        "        [540,  985 ],\n",
        "        [1620, 985 ],\n",
        "        [2160, 1920],\n",
        "        [1620, 2855],\n",
        "        [540,  2855],\n",
        "        [0,    1920]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [0,    1920],\n",
        "        [540,  985 ],\n",
        "        [0,    0   ]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1620, 985 ],\n",
        "        [2160, 1920],\n",
        "        [2160,    0]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [540,  985 ],\n",
        "        [0,    0   ],\n",
        "        [2160, 0   ],\n",
        "        [1620, 985 ]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [0,    1920],\n",
        "        [0,    3840],\n",
        "        [540,  2855]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [2160, 1920],\n",
        "        [1620, 2855],\n",
        "        [2160, 3840]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1620, 2855],\n",
        "        [540,  2855],\n",
        "        [0,    3840],\n",
        "        [2160, 3840]\n",
        "    ], np.int32)\n",
        "]\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
        "\n",
        "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
        "zone_annotators = [\n",
        "    sv.PolygonZoneAnnotator(\n",
        "        zone=zone,\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=6,\n",
        "        text_thickness=8,\n",
        "        text_scale=4\n",
        "    )\n",
        "    for index, zone\n",
        "    in enumerate(zones)\n",
        "]\n",
        "box_annotators = [\n",
        "    sv.BoundingBoxAnnotator(\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=4,\n",
        "    )\n",
        "    for index\n",
        "    in range(len(polygons))\n",
        "]\n",
        "\n",
        "generator = sv.get_video_frames_generator(VideoAssets.MARKET_SQUARE.value)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, size=1280)\n",
        "detections = sv.Detections.from_yolov5(results)\n",
        "detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
        "\n",
        "for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
        "    mask = zone.trigger(detections=detections)\n",
        "    detections_filtered = detections[mask]\n",
        "    frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
        "    frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "%matplotlib inline\n",
        "sv.plot_image(frame, (16, 16))"
      ],
      "metadata": {
        "id": "MFO_DXFyqCSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = sv.ColorPalette.DEFAULT\n",
        "polygons = [\n",
        "    np.array([\n",
        "        [540,  985 ],\n",
        "        [1620, 985 ],\n",
        "        [2160, 1920],\n",
        "        [1620, 2855],\n",
        "        [540,  2855],\n",
        "        [0,    1920]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [0,    1920],\n",
        "        [540,  985 ],\n",
        "        [0,    0   ]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1620, 985 ],\n",
        "        [2160, 1920],\n",
        "        [2160,    0]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [540,  985 ],\n",
        "        [0,    0   ],\n",
        "        [2160, 0   ],\n",
        "        [1620, 985 ]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [0,    1920],\n",
        "        [0,    3840],\n",
        "        [540,  2855]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [2160, 1920],\n",
        "        [1620, 2855],\n",
        "        [2160, 3840]\n",
        "    ], np.int32),\n",
        "    np.array([\n",
        "        [1620, 2855],\n",
        "        [540,  2855],\n",
        "        [0,    3840],\n",
        "        [2160, 3840]\n",
        "    ], np.int32)\n",
        "]\n",
        "video_info = sv.VideoInfo.from_video_path(VideoAssets.MARKET_SQUARE.value)\n",
        "\n",
        "zones = [sv.PolygonZone(polygon=polygon) for polygon in polygons]\n",
        "zone_annotators = [\n",
        "    sv.PolygonZoneAnnotator(\n",
        "        zone=zone,\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=6,\n",
        "        text_thickness=8,\n",
        "        text_scale=4\n",
        "    )\n",
        "    for index, zone\n",
        "    in enumerate(zones)\n",
        "]\n",
        "box_annotators = [\n",
        "    sv.BoundingBoxAnnotator(\n",
        "        color=colors.by_idx(index),\n",
        "        thickness=4,\n",
        "    )\n",
        "    for index\n",
        "    in range(len(polygons))\n",
        "]\n",
        "\n",
        "def process_frame(frame: np.ndarray, i) -> np.ndarray:\n",
        "    # detect\n",
        "    results = model(frame, size=1280)\n",
        "    detections = sv.Detections.from_yolov5(results)\n",
        "    detections = detections[(detections.class_id == 0) & (detections.confidence > 0.5)]\n",
        "\n",
        "    for zone, zone_annotator, box_annotator in zip(zones, zone_annotators, box_annotators):\n",
        "        mask = zone.trigger(detections=detections)\n",
        "        detections_filtered = detections[mask]\n",
        "        frame = box_annotator.annotate(scene=frame, detections=detections_filtered)\n",
        "        frame = zone_annotator.annotate(scene=frame)\n",
        "\n",
        "    return frame\n",
        "\n",
        "sv.process_video(source_path=VideoAssets.MARKET_SQUARE.value, target_path=f\"{HOME}/market-square-result.mp4\", callback=process_frame)\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "S1G1i3w0qHr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}